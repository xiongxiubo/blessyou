import { App } from "antd";

interface UseRefCanvasRecorderOptions {
  autoDownload?: boolean;
  backgroundImage?: string | null; // æ”¯æŒ URL æˆ– base64 å›¾ç‰‡
  scale?: number; // è¾“å‡ºæ¸…æ™°åº¦å€ç‡ï¼ˆ1=åŸç”»ï¼Œ2=2Kï¼Œ4=4Kï¼‰
}

export function useRefCanvasRecorder({ autoDownload = true, backgroundImage = null, scale = 2 }: UseRefCanvasRecorderOptions = {}) {
  const recorderRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<BlobPart[]>([]);
  const [recording, setRecording] = useState(false);
  const [videoData, setVideoData] = useState<Blob | null>(null);
  const { uploadVideo } = useApi();
  const { message } = App.useApp();
  // ä¸‹è½½é”
  const downloadLock = useRef(false);

  // ğŸ”Š Base64 PCM â†’ 16kHz AudioBuffer
  const base64ToAudioBuffer = useCallback(async (base64: string, audioContext: AudioContext) => {
    const binary = atob(base64);
    const buffer = new ArrayBuffer(binary.length);
    const view = new Uint8Array(buffer);
    for (let i = 0; i < binary.length; i++) view[i] = binary.charCodeAt(i);

    const samples = new Float32Array(binary.length / 2);
    const dv = new DataView(buffer);
    for (let i = 0; i < samples.length; i++) {
      samples[i] = dv.getInt16(i * 2, true) / 0x8000;
    }

    // ğŸ§© åœ¨éŸ³é¢‘å¤´éƒ¨æ’å…¥ 100ms é™éŸ³
    const sampleRate = 16000;
    const silentSamplesCount = Math.floor(sampleRate * 0.1);
    const paddedSamples = new Float32Array(silentSamplesCount + samples.length);
    paddedSamples.set(samples, silentSamplesCount);

    const audioBuffer = audioContext.createBuffer(1, paddedSamples.length, sampleRate);
    audioBuffer.copyToChannel(paddedSamples, 0);

    return audioBuffer;
  }, []);

  const findCanvasInRef = useCallback((ref: React.RefObject<HTMLElement | null>) => {
    if (!ref.current) return null;
    return ref.current.querySelector("canvas");
  }, []);

  const startRecording = useCallback(
    async (containerRef: React.RefObject<HTMLElement | null>, base64PCM: string) => {
      const canvas = findCanvasInRef(containerRef);
      if (!canvas) {
        console.error("No <canvas> element found inside the given ref.");
        return;
      }
      const originalStream = canvas.captureStream(60);
      let finalStream: MediaStream;

      // ğŸ¨ å¤„ç†èƒŒæ™¯å›¾ä¸é«˜æ¸…è¾“å‡º
      const upscaleCanvas = document.createElement("canvas");
      upscaleCanvas.width = canvas.width * scale;
      upscaleCanvas.height = canvas.height * scale;
      const upscaleCtx = upscaleCanvas.getContext("2d")!;

      // å¦‚æœæœ‰èƒŒæ™¯å›¾ï¼ŒåŠ è½½ä¸€æ¬¡
      let bgImage: HTMLImageElement | null = null;
      if (backgroundImage) {
        bgImage = new Image();
        bgImage.crossOrigin = "anonymous";
        bgImage.src = backgroundImage;

        await new Promise<void>(resolve => {
          bgImage!.onload = () => resolve();
          bgImage!.onerror = () => {
            console.warn("[useRefCanvasRecorder] èƒŒæ™¯å›¾ç‰‡åŠ è½½å¤±è´¥ï¼Œè·³è¿‡ã€‚");
            resolve();
          };
        });
      }

      // ç”¨è§†é¢‘ä¸­é—´å±‚æ‰¿æ¥ canvas ç”»é¢
      const video = document.createElement("video");
      video.srcObject = new MediaStream([originalStream.getVideoTracks()[0]]);
      await video.play();

      // ğŸ¬ å¾ªç¯ç»˜åˆ¶é«˜åˆ†è¾¨ç‡ç”»é¢
      const drawLoop = () => {
        if (bgImage) upscaleCtx.drawImage(bgImage, 0, 0, upscaleCanvas.width, upscaleCanvas.height);
        upscaleCtx.drawImage(video, 0, 0, upscaleCanvas.width, upscaleCanvas.height);
        requestAnimationFrame(drawLoop);
      };
      drawLoop();

      // ğŸ¥ ä»éšè—çš„é«˜åˆ†è¾¨ç‡ canvas æ•è·è§†é¢‘æµ
      finalStream = upscaleCanvas.captureStream(60);

      // âœ… ç¨å¾®ç­‰å¾…æ¸²æŸ“ç¨³å®š
      await new Promise(r => setTimeout(r, 300));

      // ğŸ§ éŸ³é¢‘éƒ¨åˆ†ï¼ˆ16kHzï¼‰
      const audioContext = new AudioContext({ sampleRate: 16000 });
      const destination = audioContext.createMediaStreamDestination();
      const audioBuffer = await base64ToAudioBuffer(base64PCM, audioContext);
      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(destination);

      // ğŸ”— åˆå¹¶éŸ³è§†é¢‘æµ
      const combinedStream = new MediaStream([...finalStream.getVideoTracks(), ...destination.stream.getAudioTracks()]);

      // æ£€æŸ¥å¯ç”¨ç±»å‹ï¼ˆå…¼å®¹ iOS Safariï¼‰
      let mimeType;

      if (MediaRecorder.isTypeSupported("video/webm;codecs=vp9")) {
        mimeType = "video/webm;codecs=vp9";
      } else if (MediaRecorder.isTypeSupported("video/webm;codecs=vp8")) {
        mimeType = "video/webm;codecs=vp8";
      } else if (MediaRecorder.isTypeSupported("video/mp4;codecs=h264")) {
        mimeType = "video/mp4;codecs=h264";
      } else {
        mimeType = ""; // Safari ä¼šè‡ªåŠ¨é€‰æ‹©å¯ç”¨æ ¼å¼
      }

      const recorder = new MediaRecorder(combinedStream, {
        mimeType,
        // videoBitsPerSecond: 10_000_000, // iPhone å¸¦å®½æœ‰é™ï¼Œå¯é€‚å½“é™ä½
      });

      recorderRef.current = recorder;
      chunksRef.current = [];
      setRecording(true);

      recorder.ondataavailable = e => {
        if (e.data.size > 0) chunksRef.current.push(e.data);
      };

      recorder.onstop = async () => {
        const blob = new Blob(chunksRef.current, { type: "video/webm" });
        setVideoData(blob);

        setRecording(false);
        source.disconnect();
        audioContext.close();
      };

      // âœ… å¯åŠ¨å½•åˆ¶ä¸éŸ³é¢‘åŒæ­¥
      recorder.start();
      source.start();
      source.onended = () => recorder.stop();
    },
    [findCanvasInRef, base64ToAudioBuffer, autoDownload, backgroundImage, scale],
  );
  const downloadVideo = useCallback(async () => {
    if (downloadLock.current) return;

    try {
      if (videoData) {
        // æŠŠvideoData å˜æˆurl
        // const videoUrl = URL.createObjectURL(videoData);
        // const a = document.createElement("a");
        // a.href = videoUrl;
        // a.download = `video_${Date.now()}.mp4`;
        // a.click();
        // URL.revokeObjectURL(videoUrl);
        const formData = new FormData();
        formData.append("file", videoData);
        message.loading({
          content: "æ­£åœ¨ä¸‹è½½è§†é¢‘è¯·ç¨å",
          key: "download",
          duration: 0,
        });
        downloadLock.current = true;

        const res = await uploadVideo(formData);
        if (res) {
          const a = document.createElement("a");
          a.href = URL.createObjectURL(new Blob([res], { type: "video/mp4" }));
          a.download = `video_${Date.now()}.mp4`;
          a.click();
          URL.revokeObjectURL(a.href);
          message.destroy("download");
        }
      }
    } catch (error) {
      throw error;
    } finally {
      downloadLock.current = false;
    }
  }, [videoData, recorderRef]);

  const stopRecording = useCallback(() => {
    if (recorderRef.current && recording) {
      recorderRef.current.stop();
    }
  }, [recording]);

  return {
    startRecording,
    stopRecording,
    downloadVideo,
  };
}
